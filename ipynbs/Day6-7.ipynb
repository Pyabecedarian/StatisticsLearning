{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What I leanrt\n",
    "- Linear Regression\n",
    "    - Squared Error\n",
    "    - Coefficient of Determination\n",
    "    \n",
    "- Covariance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If n points $\\{ (x_1,y1), (x_2,y_2), ... (x_n, y_n) \\}$ in a coordinate plane, one can fit a line $( y = mx + b )$ to these points by minimizing the Squard Error from each point to the line.\n",
    "\n",
    "#### Squared Error:  \n",
    "\n",
    "$\\qquad \\displaystyle SE_{LINE} = \\sum_i^n {[y_i - (mx_i+b)]^2}$  \n",
    "\n",
    "The question now is to find $m$ and $b$ to minimizing $SE_{LINE}$.  \n",
    "\n",
    "Expend the inner terms, we get:  \n",
    "\n",
    "$\\qquad \\displaystyle \\begin {align} SE_{LINE} &=  \\sum_i^n {[y_i - (mx_i+b)]^2} \\\\ \n",
    "&= \\sum_i^n {y_i^2 - 2y_i(mx_i+b) + (mx_i+b)^2} \\\\\n",
    "&= \\sum_i^n {\\underbrace {y_i^2}_{n \\cdot \\overline{y^2}} - 2m\\underbrace{y_ix_i}_{n \\cdot \\overline{xy}} - 2\\underbrace{y_i}_{n \\cdot \\overline{y}}b + m^2\\underbrace{x_i^2}_{n \\cdot \\overline{x^2}} + 2\\underbrace{mx_i}_{n \\cdot \\overline{x}}b + b^2 } \\\\  \n",
    "&= n\\overline{y^2} -2mn\\overline{xy} - 2bn\\overline{y} + m^2n\\overline{x^2} + 2mbn\\overline{x} + nb^2 \\end {align}$  \n",
    "\n",
    "<br>\n",
    "\n",
    "The minimum would lies at the point$(m, b)$, where:  \n",
    "\n",
    "$\\qquad \\displaystyle \\frac {\\partial{SE}}{\\partial m} = 0 $  \n",
    "\n",
    "$\\qquad \\displaystyle \\frac {\\partial {SE}}{\\partial b} = 0$  \n",
    "\n",
    "\n",
    "Simplify the equation, we have:  \n",
    "\n",
    "$\\qquad \\displaystyle \\begin {cases} m\\overline{x^2} + b\\overline{x} = \\overline{xy} \\quad \\to \\quad (\\frac{\\overline{x^2}}{\\overline{x}}, \\frac{\\overline{xy}}{\\overline{x}}) \\, \\text {lies on the line}\\\\\n",
    "m\\overline{x} + b = \\overline{y}  \\quad \\to \\quad  (\\overline{x}, \\overline{y}) \\, \\text {lies on the line} \\end {cases}$   \n",
    "\n",
    "\n",
    "Solve for $m$ and $b$:  \n",
    "\n",
    "$\\qquad \\displaystyle m = \\frac {\\overline{x}\\cdot\\overline{y} - \\overline{xy}}{(\\overline{x})^2 - \\overline{x^2}}$  \n",
    "\n",
    "$\\qquad \\displaystyle b = \\overline{y} - m\\overline{x}$  \n",
    "\n",
    "\n",
    "#### Coefficient of Determination $r^2$\n",
    "*To measure how good the fitting line is, one can estimate how much (what %) of the \"total variation\" in $y$ is described by variation in $x$.*  \n",
    "\n",
    "Total Variation in $y$:   \n",
    "\n",
    "$\\qquad \\displaystyle SE_{\\overline{y}} = \\sum (yi - \\overline{y})^2$  \n",
    "\n",
    "Variation in $x$:   \n",
    "\n",
    "$\\qquad SE_{LINE}$  \n",
    "\n",
    "The % of Total Variation in $y$ is not described by Variation in $x$:  \n",
    "\n",
    "$\\qquad \\displaystyle \\frac {SE_{LINE}}{SE_{\\overline{y}}} $  \n",
    "\n",
    "Reversely saying, the % of variation in $y$ been desribed is:  \n",
    "\n",
    "$\\qquad \\displaystyle r^2 = 1 - \\frac {SE_{LINE}}{SE_{\\overline{y}}}$  \n",
    "\n",
    "It's easy to figure out that the range of $r^2$ is $(0, 1)$. When the line fits so well, then $r^2 \\to 1, otherwise \\,r^2 \\to 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Covariance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Covariance is an Expected value of the product of distances of each r.v from their mean.*  \n",
    "\n",
    "$\\quad \\begin {align} Cov(X,Y) &= E[ (X-E[X])(Y-E[Y]) ] \\\\ \n",
    "&= E[XY - XE[Y] - E[X]Y + E[X]E[Y]] \\\\ \n",
    "&= E[XY] - E[X]E[Y] \\\\ \n",
    "&= \\underbrace {\\overline{xy} - \\overline{x}\\cdot \\overline{y}}_{\\text {numerator of m}}\n",
    "\\end {align}$  \n",
    "\n",
    "So rewrite the slope of fitting line as:  \n",
    "\n",
    "$\\qquad \\displaystyle m= \\frac {\\overline{x}\\cdot\\overline{y} - \\overline{xy}}{(\\overline{x})^2 - \\overline{x^2}} = \\frac {Cov(X, Y)}{Cov(X, X)} = \\frac {Cov(X,Y)}{Var(X)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What I learnt\n",
    "- $\\chi^2$ Distribution\n",
    "- $\\chi^2$ Hypothesis Test\n",
    "    - $\\chi^2$ statistic\n",
    "- Contingency Table\n",
    "- Analysis of Variance\n",
    "    - SST\n",
    "    - SSW\n",
    "    - SSB\n",
    "- F-Statistic\n",
    "- Causality & Correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\chi^2$ Distribution\n",
    "\n",
    "\n",
    "<img src=\"./imgs/chiSquareDistributionPDF.png\" width=\"45%\" height=\"55%\" align=\"right\">  \n",
    "*$\\chi^2$ is used to estimate how well the theoretic distribution explains the observed ones,   \n",
    "or how good a fit observed results are for the theoretical distribitions.*  \n",
    " \n",
    "If $\\{ X_i\\}$ are **Independent Normally Distributed** R.V.s(ie. $X_i \\, \\sim \\, N(0, 1)$): \n",
    "\n",
    "Let $Q$ is the sum of $X_i^2$, $\\quad \\displaystyle Q = \\sum_{i=1}^n X_i^2$,\n",
    "\n",
    "then $\\, Q \\sim \\chi^2_n , \\,$ where $\\, n \\, \\text {is \"Degrees of Freedom\"}$  \n",
    "\n",
    "\n",
    "<br>  \n",
    "\n",
    "### Pearson's  $\\chi^2$ statistic  \n",
    "$\\displaystyle \\chi^2 = \\sum_{i=1}^{n}\\frac {(O_i-E_i)^2}{E_i}$   \n",
    "\n",
    "<br> \n",
    "\n",
    "### Table of Ï‡2 values vs p-values  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./imgs/chiSquareTable.png\" width=\"65%\" height=\"65%\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contingency Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./imgs/contingencyTable.png\" width=\"55%\" height=\"55%\" align=\"right\">\n",
    "\n",
    "*In statistics, a contingency table (aka. a cross tabulation or crosstab) is a type of table in a matrix format that displays the (multivariate) frequency distribution of the variables.*\n",
    "\n",
    "#### Steps of $\\chi^2$ Hypothesis Test:\n",
    "- Formulate $H_0$ and $H_1$\n",
    "- Set significance level $\\alpha$\n",
    "- Construbt contingency table assuming $H_0$ is true\n",
    "- Calculate $\\chi^2$ statistic and determine degrees of freedom n\n",
    "- Find the critical $\\chi^2$ statistic from $\\chi^2$ P-value table\n",
    "- Compare these two $\\chi^2$ statistic, then accept or reject"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of Variance (ANOVA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./imgs/varianceAnalysis.png\" width=\"55%\" height=\"55%\" align=\"right\">\n",
    "\n",
    "Assuming the table contains $m$ columns and $n$ rows:  \n",
    "\n",
    "***Mean of total numbers***: $\\, \\displaystyle \\overline{\\overline{X}} = \\frac {\\sum_{j}^m \\sum_{i}^n x_{ij}}{mn} $  \n",
    "\n",
    "***Mean of each column***: $\\, \\displaystyle \\overline {X_j} = \\frac {\\sum_i^n {x_{ij}}}{n}$\n",
    "\n",
    "\n",
    "### Sum of Squares Total (SST)\n",
    "*Kind of like the numerator of calculating variance.*  \n",
    "$\\qquad \\displaystyle SST = \\sum_j^m \\sum_i^n (x_{ij} - \\overline{\\overline{X}})^2, \\quad d.f.=mn-1 $   \n",
    "\n",
    "### Sum of Squares Within (SSW)\n",
    "$\\qquad \\displaystyle SSW = \\sum_j^m \\sum_i^n (x_{ij}-\\overline {X_j})^2, \\quad d.f.=m(n-1)$\n",
    "\n",
    "### Sum of Squares Between (SSB)\n",
    "$\\qquad \\displaystyle SSB = \\sum_j^m n(\\overline {X_j} - \\overline{\\overline{X}})^2, \\quad d.f.=m-1$  \n",
    "\n",
    "It turns out that **SST** is composed of the these two parts: $SST = SSW + SSB$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F-Statistic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./imgs/F-test.png\" width=\"55%\" height=\"55%\" align=\"right\">\n",
    "\n",
    "*F Distribution is a ratio of $\\chi^2$ two Distribution*   \n",
    "\n",
    "$\\qquad \\displaystyle F-Statistic = \\frac { \\displaystyle \\frac{SSB}{d.f._{SSB}}}{ \\displaystyle \\frac{{SSW}}{d.f._{SSW}}}$  \n",
    "\n",
    "F-Test is the same as other hypothesis tests except it has 2 different degrees of freedom."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Causality & Correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If $A$ is causality to $B$, then $A$ is the reason that $B$ happens.  \n",
    "If $C$ is correlation to $D$, then $C$ and $D$ can be observed in the same time whenever either happens, but $C$ is not the reason causing $D$ happens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inductive Reasoning & Deductive Reasoning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inductive Reasoning\n",
    "*Looking for a pattern or trend, then generalizing (extrapolating the information)*  \n",
    "\n",
    "#### Deductive Reasoning\n",
    "*Make use of some data and facts,then come up with some other facts that are surly true*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
